{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('py-effective-py': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "bf53ecf2be5b0c89778fbd17a3e30ef364a8b92138249caa59ed972682d3f38a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Item 39 Use @classmethod Polymorphism to Construct Objects Generically\n",
    "\n",
    "Things to Remember\n",
    "- Python only supports a single constructor per class: the __init__ method.\n",
    "- Use @classmethod to define alternative constructors for your classes.\n",
    "- Use class method polymorphism to provide generic ways to build and connect many concrete subclasses.   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Background\n",
    "- MapReduce is a programming model and an associated implementation for processing and generating big data sets with a parallel, distributed algorithm on a cluster\n",
    "\n",
    "- A MapReduce program is composed of a map procedure, which performs filtering and sorting (such as sorting students by first name into queues, one queue for each name), and a reduce method, which performs a summary operation (such as counting the number of students in each queue, yielding name frequencies)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you are writing a MapReduce implementation\n",
    "\n",
    "class InputData: # a common class represents the input data\n",
    "    def read(self):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a concrete subclass that reads data from a file on disk\n",
    "class PathInputData(InputData):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "    def read(self):\n",
    "        with open(self.path) as f:\n",
    "            return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - abstract interface for the MapReduce worker\n",
    "#   that consumes the input data in a standard\n",
    "#   way \n",
    "\n",
    "class Worker:\n",
    "    def __init__(self, input_data):\n",
    "        self.input_data = input_data\n",
    "        self.result = None\n",
    "    def map(self):\n",
    "        raise NotImplementedError\n",
    "    def reduce(self, other):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple newline counter\n",
    "class LineCountWorker(Worker):\n",
    "    def map(self):\n",
    "        data = self.input_data.read()\n",
    "        self.result = data.count('\\n')\n",
    "    def reduce(self, other):\n",
    "        self.result += other.result"
   ]
  },
  {
   "source": [
    "Now we need something that is responsible for building the objects and orchestrating the MapReduce\n",
    "- using helper functions\n",
    "- class method polymorphism"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def generate_inputs(data_dir):\n",
    "    for name in os.listdir(data_dir):\n",
    "        yield PathInputData(os.path.join(data_dir, name)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_workers(input_list):\n",
    "    workers = []\n",
    "    for input_data in input_list:\n",
    "        workers.append(LineCountWorker(input_data))\n",
    "    return workers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fan out the map step (check Item 53)\n",
    "from threading import Thread\n",
    "\n",
    "def execute(workers):\n",
    "    threads = [Thread(target=w.map) for w in workers]\n",
    "    for thread in threads: thread.start()\n",
    "    # join: asks main thread to wait until\n",
    "    #       everyone is done.\n",
    "    for thread in threads: thread.join()\n",
    "\n",
    "    first, *rest = workers\n",
    "    for worker in rest:\n",
    "        first.reduce(worker)\n",
    "    return first.result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect all the pieces together\n",
    "def mapreduce(data_dir):\n",
    "    inputs = generate_inputs(data_dir)\n",
    "    workers = create_workers(inputs)\n",
    "    return execute(workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "\n",
    "def write_test_files(tmpdir):\n",
    "    if os.path.isdir(tmpdir):\n",
    "        shutil.rmtree(tmpdir)\n",
    "    os.makedirs(tmpdir)\n",
    "    for i in range(100):\n",
    "        # - create a new file with a random number of \n",
    "        #   new lines \n",
    "        with open(os.path.join(tmpdir, str(i)), 'w') as f:\n",
    "            f.write('\\n' * random.randint(0, 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = 'test_inputs'\n",
    "write_test_files(tmpdir)\n",
    "result = mapreduce(tmpdir)\n",
    "print(f'There are {result} lines') "
   ]
  },
  {
   "source": [
    "Problems with the above approach\n",
    "- the mapreduce function is not generic; you have to rewrite generate_input and create_workers, and mapreduce to match if you need to add new InputData or Worker subclass\n",
    "- you can't solve the problem with constructor polymorphism as Python only allows for the single constructor method \\__init\\__ and it's unreasonable to require every InputData subclass to have a compatible constructor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class method polymorphism \n",
    "\n",
    "# - move generate_inputs into\n",
    "#   the base class\n",
    "class GenericInputData:\n",
    "    def read(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # - static factory pattern\n",
    "    # - subclass need to decide how \n",
    "    #   an instance is created and\n",
    "    #   interpret what is in the\n",
    "    #   config dict\n",
    "    # - cls is the generic constructor \n",
    "\n",
    "    @classmethod\n",
    "    def generate_inputs(cls, config):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathInputData(GenericInputData):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "    def read(self):\n",
    "        with open(self.path) as f:\n",
    "            return f.read()\n",
    "    # - determine how the instances\n",
    "    #   are created\n",
    "    @classmethod\n",
    "    def generate_inputs(cls, config):\n",
    "        data_dir = config['data_dir']\n",
    "        # - return an instance for each\n",
    "        #   file in the dir \n",
    "        for name in os.listdir(data_dir):\n",
    "            yield cls(os.path.join(data_dir, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenericWorker:\n",
    "    def __init__(self, input_data):\n",
    "        self.input_data = input_data\n",
    "        self.result = None\n",
    "    def map(self):\n",
    "        raise NotImplementedError\n",
    "    def reduce(self, other):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    @classmethod\n",
    "    def create_workers(cls, input_class, config):\n",
    "        workers = []\n",
    "        # - construct instances of the GenericWorker subclass\n",
    "        # - we use input_class.generate_inputs to achieve\n",
    "        #   class polymorphism \n",
    "        for input_data in input_class.generate_inputs(config):\n",
    "            workers.append(cls(input_data))\n",
    "        return workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the parent class\n",
    "class LineCountWorker(GenericWorker):\n",
    "    def map(self):\n",
    "        data = self.input_data.read()\n",
    "        self.result = data.count('\\n')\n",
    "    def reduce(self, other):\n",
    "        self.result += other.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - the generic version\n",
    "# - you can now add more subclasses without\n",
    "#   the need to modify this method\n",
    "def mapreduce(worker_class, input_class, config):\n",
    "    workers = worker_class.create_workers(input_class, config)\n",
    "    return execute(workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = 'test_inputs'\n",
    "write_test_files(tmpdir)\n",
    "config = { 'data_dir' : tmpdir}\n",
    "result = mapreduce(LineCountWorker, PathInputData, config)\n",
    "print(f'There are {result} lines')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}